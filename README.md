## ğŸŒ¦ï¸ Airflow Clima â€“ Pipeline de Coleta de Dados MeteorolÃ³gicos

DAG do Apache Airflow para coletar dados da API Meteoblue, processÃ¡-los com Pandas e salvar arquivos CSV datados em execuÃ§Ã£o automÃ¡tica semanal.

### ğŸ” Etapas do Pipeline
1ï¸. ExtraÃ§Ã£o â€“ API Meteoblue
- Endpoint utilizado: packages/basic-day
- ParÃ¢metros fixos: latitude, longitude, altitude e formato JSON
- Dados retornados: previsÃ£o/resumo diÃ¡rio (data_day)

2ï¸. TransformaÃ§Ã£o â€“ Python
- ConversÃ£o do JSON em DataFrame
- SeleÃ§Ã£o e visualizaÃ§Ã£o inicial dos dados
- ConversÃ£o para dicionÃ¡rio (compatÃ­vel com XCom)

3. Carga â€“ CSV
- GeraÃ§Ã£o de um arquivo CSV com timestamp baseado na execuÃ§Ã£o do DAG
- Estrutura: clima_YYYYMMDD.csv
- Local de saÃ­da: /home/barbara/projetos_linux/airflow_clima/

### â–¶ï¸ Como Executar
1. Ativar o ambiente virtual  
source venv/bin/activate

3. Iniciar o Airflow  
   airflow standalone

5. Verificar a DAG no UI  
   Acessar: http://localhost:8080  
   A DAG aparecerÃ¡ como clima_dag

### ğŸ“… Agendamento
- ExecuÃ§Ã£o automÃ¡tica toda sexta-feira Ã s 09:00
- schedule="0 9 * * 5"

### ğŸ› ï¸ Tecnologias
Apache Airflow Â· Python Â· Pandas Â· Requests

### ğŸ“‚ Estrutura do RepositÃ³rio
    airflow_clima/
    â”‚
    â”œâ”€â”€ dags/
    â”‚   â””â”€â”€ clima_dag.py
    â””â”€â”€ output/
        â””â”€â”€ clima_YYYYMMDD.csv  # arquivos gerados
